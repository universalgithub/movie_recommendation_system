{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEKiBW0lJzpVD1yQeFDO0i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abiralchy0987/movie_recommendation_system/blob/main/Accuracy_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Content filtering\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import os\n",
        "\n",
        "#reading the data\n",
        "movies = pd.read_csv('/content/tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('/content/tmdb_5000_credits.csv')\n",
        "\n",
        "movies.head(2)\n",
        "\n",
        "#head shows only one row of the dataset because of the parameter (1)\n",
        "credits.head(1)\n",
        "\n",
        "movies.shape\n",
        "\n",
        "#shape shows how many rows and columns are available in the dataset\n",
        "credits.shape\n",
        "\n",
        "#integration of datasets movies and credits\n",
        "movies = movies.merge(credits , on = 'title')\n",
        "\n",
        "movies.head(1)\n",
        "\n",
        "#visualising the integrated datasets\n",
        "#previously movies had 20 columns and credits had four columns and since\n",
        "#it was integrated on the column \"title\" which was same on both the datasets\n",
        "#the new number of columns present is 23\n",
        "movies.shape\n",
        "\n",
        "\n",
        "movies.columns\n",
        "\n",
        "#cleaning data\n",
        "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
        "\n",
        "#data preprocessing\n",
        "#checking for missing values\n",
        "movies.isnull().sum()\n",
        "\n",
        "#dropping the rows with missing value because there is very small number of data with missing value\n",
        "movies.dropna(inplace=True)\n",
        "\n",
        "movies.duplicated().sum()\n",
        "\n",
        "movies.iloc[0]['genres']\n",
        "\n",
        "import ast\n",
        "def convert(text):\n",
        "  l=[]\n",
        "  for i in ast.literal_eval(text):\n",
        "    l.append(i['name'])\n",
        "\n",
        "  return l\n",
        "\n",
        "\n",
        "movies['genres']=movies['genres'].apply(convert)\n",
        "\n",
        "movies['keywords']=movies['keywords'].apply(convert)\n",
        "\n",
        "import ast\n",
        "def convert_cast(text):\n",
        "  l=[]\n",
        "  counter=0\n",
        "  for i in ast.literal_eval(text):\n",
        "    if counter<3:\n",
        "     l.append(i['name'])\n",
        "    counter+=1\n",
        "\n",
        "  return l\n",
        "\n",
        "movies['cast']=movies['cast'].apply(convert_cast)\n",
        "\n",
        "import ast\n",
        "def fetch_director(text):\n",
        "  l=[]\n",
        "  for i in ast.literal_eval(text):\n",
        "    if i['job'] == 'Director':\n",
        "     l.append(i['name'])\n",
        "     break\n",
        "\n",
        "  return l\n",
        "\n",
        "movies['crew']=movies['crew'].apply(fetch_director)\n",
        "\n",
        "\n",
        "\n",
        "movies['overview']=movies['overview'].apply(lambda x:x.split())\n",
        "\n",
        "def remove_space(word):\n",
        "  l = []\n",
        "  for i in word:\n",
        "    l.append(i.replace(\" \",\"\"))\n",
        "  return l\n",
        "\n",
        "\n",
        "movies['cast']=movies['cast'].apply(remove_space)\n",
        "\n",
        "movies['crew']=movies['crew'].apply(remove_space)\n",
        "\n",
        "movies['tags']= movies['overview']+movies['keywords']+movies['genres']+movies['cast']+movies['crew']\n",
        "\n",
        "new_df = movies[['movie_id','title','tags']]\n",
        "\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "def stem(text):\n",
        "  l = []\n",
        "  for i in text.split():\n",
        "    l.append(ps.stem(i))\n",
        "\n",
        "  return \" \".join(l)\n",
        "\n",
        "new_df['tags'] = new_df['tags'].apply(stem)\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "words_clean=[]\n",
        "for word in new_df['tags']:\n",
        " stopwords = nltk.corpus.stopwords.words('english')\n",
        "if word not in stopwords:\n",
        "     l = []\n",
        "for i in word.split():\n",
        "     l.append(ps.stem(i))\n",
        "     words_clean.append(\" \".join(l))\n",
        "else:\n",
        "         words_clean.append(word)\n",
        "         print(words_clean)\n",
        "# def stem(text):\n",
        "#   l = []\n",
        "#   for i in text.split():\n",
        "#     l.append(ps.stem(i))\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=5000,stop_words='english')\n",
        "vector= cv.fit_transform(new_df['tags']).toarray()\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity = cosine_similarity(vector)\n",
        "similarity\n",
        "\n",
        "new_df[new_df['title'] == 'Spider-Man'].index[0]\n",
        "\n",
        "def recommend(movie):\n",
        "  movie_index = new_df[new_df['title'] == movie].index[0]\n",
        "  distances =sorted(list(enumerate(similarity[movie_index])),reverse=True, key = lambda x: x[1])\n",
        "  for i in distances[1:6]:\n",
        "    print(new_df.iloc[i[0]].title)\n",
        "\n",
        "\n",
        "recommend('Spider-Man')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "611CRMkq9908",
        "outputId": "9c0810ba-a932-4390-9d07-d708fb77d4d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-bc96b97cf622>:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
            "<ipython-input-2-bc96b97cf622>:110: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())\n",
            "<ipython-input-2-bc96b97cf622>:122: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['tags'] = new_df['tags'].apply(stem)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ever', 'ever sinc', 'ever sinc the', 'ever sinc the second', 'ever sinc the second grade', 'ever sinc the second grade when', 'ever sinc the second grade when he', 'ever sinc the second grade when he first', 'ever sinc the second grade when he first saw', 'ever sinc the second grade when he first saw her', 'ever sinc the second grade when he first saw her in', 'ever sinc the second grade when he first saw her in e.t.', 'ever sinc the second grade when he first saw her in e.t. the', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial,', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore.', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now,', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year', 'ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later', \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he'\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date.\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there'\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem:\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she'\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's,\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well,\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger,\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey.\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl documentari\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl documentari drewbarrymor\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl documentari drewbarrymor brianherzl\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl documentari drewbarrymor brianherzl coreyfeldman\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzl ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl documentari drewbarrymor brianherzl coreyfeldman brianherzl\", \"ever sinc the second grade when he first saw her in e.t. the extraterrestrial, brian herzling ha had a crush on drew barrymore. now, 20 year later he' decid to tri to fulfil hi lifelong dream by ask her for a date. there' one small problem: she' drew barrymor and he's, well, brian herzlinger, a broke 27-year-old aspir filmmak from new jersey. obsess camcord crush dream girl documentari drewbarrymor brianherzling coreyfeldman brianherzling\"]\n",
            "Spider-Man 3\n",
            "Spider-Man 2\n",
            "The Amazing Spider-Man 2\n",
            "Arachnophobia\n",
            "The Amazing Spider-Man\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collaborative filtering\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "movies_df = pd.read_csv('movies.csv')\n",
        "ratings_df = pd.read_csv('ratings.csv')\n",
        "\n",
        "ratings_df.shape\n",
        "\n",
        "movies_df.head(1)\n",
        "\n",
        "ratings_df.head(1)\n",
        "\n",
        "movies = pd.merge(ratings_df, movies_df, on='movieId')\n",
        "\n",
        "\n",
        "# Remove duplicates if any\n",
        "movies = movies.drop_duplicates()\n",
        "\n",
        "\n",
        "# Create the User-Item Rating Matrix (pivot table)\n",
        "user_item_matrix = movies.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# Display the shape and first few entries of the matrix\n",
        "print(user_item_matrix.shape)\n",
        "print(user_item_matrix.head())\n",
        "\n",
        "\n",
        "# Calculate the global average rating\n",
        "global_avg_rating = movies['rating'].mean()\n",
        "\n",
        "# Fill NaN values with the global average rating\n",
        "user_item_matrix_filled = user_item_matrix.fillna(global_avg_rating)\n",
        "\n",
        "\n",
        "user_item_matrix_filled.head(1)\n",
        "\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Prepare data for Surprise\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(movies[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Split data into train and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Initialize SVD model\n",
        "svd = SVD()\n",
        "\n",
        "# Train the model\n",
        "svd.fit(trainset)\n",
        "\n",
        "# Predict ratings on the testset\n",
        "predictions = svd.test(testset)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "\n",
        "# Predict the rating for a specific user-item pair\n",
        "user_id = 1  # Example user\n",
        "movie_id = 50  # Example movie\n",
        "\n",
        "predicted_rating = svd.predict(user_id, movie_id).est\n",
        "print(f\"Predicted rating for User {user_id} on Movie {movie_id}: {predicted_rating}\")\n",
        "\n",
        "\n",
        "import heapq\n",
        "\n",
        "def recommend_movies(user_id, top_n=10):\n",
        "    \"\"\"Recommends top N movies for a specific user.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): The ID of the user.\n",
        "        top_n (int, optional): The number of movies to recommend. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of movie titles.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get all movie IDs and create a dictionary for movieId -> title lookup\n",
        "    movie_id_to_title = dict(zip(movies['movieId'], movies['title']))\n",
        "\n",
        "    # Get all unique movie IDs\n",
        "    all_movie_ids = movies['movieId'].unique()\n",
        "\n",
        "    # Get the movies that the user has already rated\n",
        "    rated_movies = set(movies[movies['userId'] == user_id]['movieId'])\n",
        "\n",
        "    # Get the unrated movies\n",
        "    unrated_movies = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n",
        "\n",
        "    # Predict ratings for unrated movies\n",
        "    predictions = [svd.predict(user_id, movie_id) for movie_id in unrated_movies]\n",
        "\n",
        "    # Sort movies by predicted rating (highest first)\n",
        "    recommended_movies = heapq.nlargest(top_n, predictions, key=lambda x: x.est)\n",
        "\n",
        "    # Get movie titles from the top N predictions using the dictionary\n",
        "    movie_titles = [movie_id_to_title[rec.iid] for rec in recommended_movies]\n",
        "\n",
        "    return movie_titles\n",
        "\n",
        "# Example usage:\n",
        "user_id = 1  # Example user ID\n",
        "recommended_movies = recommend_movies(user_id, top_n=10)\n",
        "print(f\"Top 10 movie recommendations for User {user_id}: {recommended_movies}\")\n",
        "\n",
        "user_id_input = input(\"Enter your user ID: \")\n",
        "try:\n",
        "    user_id = int(user_id_input)  # Ensure the user ID is an integer\n",
        "    recommended_movies = recommend_movies(user_id, top_n=10)\n",
        "    print(f\"Top 10 movie recommendations for User {user_id}: {recommended_movies}\")\n",
        "except ValueError:\n",
        "    print(\"Invalid input. Please enter a valid integer for user ID.\")\n"
      ],
      "metadata": {
        "id": "W4DhmPN1-WI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740cb58e-5f97-4060-efb7-7220673e971b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610, 9724)\n",
            "movieId  1       2       3       4       5       6       7       8       \\\n",
            "userId                                                                    \n",
            "1           4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
            "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "\n",
            "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
            "userId                   ...                                                   \n",
            "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "\n",
            "movieId  193583  193585  193587  193609  \n",
            "userId                                   \n",
            "1           NaN     NaN     NaN     NaN  \n",
            "2           NaN     NaN     NaN     NaN  \n",
            "3           NaN     NaN     NaN     NaN  \n",
            "4           NaN     NaN     NaN     NaN  \n",
            "5           NaN     NaN     NaN     NaN  \n",
            "\n",
            "[5 rows x 9724 columns]\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505175 sha256=f60800a30791f723a3c5fce4638432a4ee71415e64d15cc5bf681e9a706a6912\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "RMSE: 0.8726\n",
            "RMSE: 0.8725502428166245\n",
            "Predicted rating for User 1 on Movie 50: 5\n",
            "Top 10 movie recommendations for User 1: ['Shawshank Redemption, The (1994)', 'Good Will Hunting (1997)', 'Departed, The (2006)', 'Wallace & Gromit: The Best of Aardman Animation (1996)', 'Philadelphia Story, The (1940)', 'Rear Window (1954)', 'Unforgiven (1992)', 'This Is Spinal Tap (1984)', 'Spirited Away (Sen to Chihiro no kamikakushi) (2001)', 'Wallace & Gromit: The Wrong Trousers (1993)']\n",
            "Enter your user ID: 1\n",
            "Top 10 movie recommendations for User 1: ['Shawshank Redemption, The (1994)', 'Good Will Hunting (1997)', 'Departed, The (2006)', 'Wallace & Gromit: The Best of Aardman Animation (1996)', 'Philadelphia Story, The (1940)', 'Rear Window (1954)', 'Unforgiven (1992)', 'This Is Spinal Tap (1984)', 'Spirited Away (Sen to Chihiro no kamikakushi) (2001)', 'Wallace & Gromit: The Wrong Trousers (1993)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thefuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q2L5l3BSRfs",
        "outputId": "50f4487c-6114-4901-ae89-0b101abad00e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting thefuzz\n",
            "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz)\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, thefuzz\n",
            "Successfully installed rapidfuzz-3.12.1 thefuzz-0.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thefuzz import fuzz, process\n",
        "\n",
        "def find_closest_movie(title_input):\n",
        "    \"\"\"\n",
        "    Finds the closest matching movie title in new_df using fuzzy matching.\n",
        "    Both the user input and the titles are compared in lowercase.\n",
        "    \"\"\"\n",
        "    all_titles = new_df['title'].tolist()\n",
        "    # Create a lowercase version for fuzzy matching\n",
        "    all_titles_lower = [t.lower() for t in all_titles]\n",
        "    title_input_lower = title_input.lower().strip()\n",
        "\n",
        "    # Get the best match using fuzzy matching\n",
        "    best_match, score = process.extractOne(title_input_lower, all_titles_lower, scorer=fuzz.partial_ratio)\n",
        "\n",
        "    # Accept the match if the score is above a threshold (e.g., 60)\n",
        "    if score > 60:\n",
        "        # Return the original title (with proper casing) corresponding to the best match\n",
        "        match_index = all_titles_lower.index(best_match)\n",
        "        return new_df.iloc[match_index]['title']\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def hybrid_recommend(user_id, movie_title, top_n=10):\n",
        "    \"\"\"\n",
        "    Hybrid recommendation that returns half the recommendations from content-based filtering\n",
        "    and half from collaborative filtering.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): The ID of the user (for collaborative filtering).\n",
        "        movie_title (str): The movie title used for content-based filtering (input is fuzzy-matched).\n",
        "        top_n (int): Total number of recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of recommended movie titles.\n",
        "    \"\"\"\n",
        "    # Determine how many movies to take from each recommender\n",
        "    n_content = top_n // 2\n",
        "    n_collab = top_n - n_content  # This ensures if top_n is odd, collaborative gets the extra slot\n",
        "\n",
        "    # ----------- Content-Based Filtering -----------\n",
        "    # Find the closest matching movie title\n",
        "    matched_movie = find_closest_movie(movie_title)\n",
        "    if not matched_movie:\n",
        "        print(f\"Sorry, we couldn't find a close match for '{movie_title}'. Please try another title.\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Using content-based match: '{matched_movie}'\")\n",
        "\n",
        "    # Get the index for the matched movie from new_df\n",
        "    try:\n",
        "        movie_index = new_df[new_df['title'] == matched_movie].index[0]\n",
        "    except IndexError:\n",
        "        print(f\"Movie '{matched_movie}' not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    # Get similarity scores for all movies relative to the matched movie\n",
        "    content_scores = list(enumerate(similarity[movie_index]))\n",
        "    # Sort scores in descending order (most similar first)\n",
        "    content_scores = sorted(content_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Build content-based recommendation list (skip the first entry as it is the movie itself)\n",
        "    content_recs = []\n",
        "    for idx, score in content_scores[1:]:\n",
        "        rec_title = new_df.iloc[idx]['title']\n",
        "        if rec_title not in content_recs:\n",
        "            content_recs.append(rec_title)\n",
        "        if len(content_recs) >= n_content:\n",
        "            break\n",
        "\n",
        "    # ----------- Collaborative Filtering -----------\n",
        "    # Get a larger pool from collaborative filtering so we can remove any duplicates later\n",
        "    collab_pool = recommend_movies(user_id, top_n=top_n * 2)\n",
        "    # Remove any movies that already appeared in the content-based recommendations\n",
        "    collab_recs = [m for m in collab_pool if m not in content_recs]\n",
        "    # Select the top n_collab recommendations\n",
        "    collab_recs = collab_recs[:n_collab]\n",
        "\n",
        "    # ----------- Merge Recommendations -----------\n",
        "    final_recs = content_recs + collab_recs\n",
        "\n",
        "    # In case there are not enough unique recommendations, try to fill from the collaborative pool\n",
        "    if len(final_recs) < top_n:\n",
        "        extra_needed = top_n - len(final_recs)\n",
        "        extra_from_collab = [m for m in collab_pool if m not in final_recs]\n",
        "        final_recs += extra_from_collab[:extra_needed]\n",
        "\n",
        "    return final_recs\n",
        "\n",
        "# ---------------------------\n",
        "# Example Usage\n",
        "# ---------------------------\n",
        "\n",
        "# Get user input\n",
        "try:\n",
        "    user_id = int(input(\"Enter your user ID: \"))\n",
        "except ValueError:\n",
        "    print(\"Invalid user ID. Please enter an integer value.\")\n",
        "    user_id = None\n",
        "\n",
        "if user_id is not None:\n",
        "    movie_title = input(\"Enter a movie title you like: \")\n",
        "\n",
        "    recommendations = hybrid_recommend(user_id, movie_title, top_n=10)\n",
        "\n",
        "    if recommendations:\n",
        "        print(\"\\nHybrid Recommendations (50% Content-Based, 50% Collaborative):\")\n",
        "        for i, title in enumerate(recommendations, 1):\n",
        "            print(f\"{i}. {title}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhoYAJ3VSWwF",
        "outputId": "ccfb89b4-17bd-4c18-ca4c-fa6674d951ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your user ID: 1\n",
            "Enter a movie title you like: bat man\n",
            "Using content-based match: 'Batman v Superman: Dawn of Justice'\n",
            "\n",
            "Hybrid Recommendations (50% Content-Based, 50% Collaborative):\n",
            "1. Man of Steel\n",
            "2. Thor\n",
            "3. Suicide Squad\n",
            "4. Superman III\n",
            "5. Superman\n",
            "6. Shawshank Redemption, The (1994)\n",
            "7. Good Will Hunting (1997)\n",
            "8. Departed, The (2006)\n",
            "9. Wallace & Gromit: The Best of Aardman Animation (1996)\n",
            "10. Philadelphia Story, The (1940)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Root Mean Squared Error (RMSE)is a commonly used metric for evaluating the accuracy of predicted ratings in collaborative filtering. It measures the difference between predicted and actual ratings.\n",
        "\n",
        "from surprise import accuracy\n",
        "\n",
        "# Assuming you have already trained your model and made predictions\n",
        "predictions = svd.test(testset)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f'RMSE: {rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLQ1RNLzTFKK",
        "outputId": "47e40d46-5bf4-4ca0-e6b3-bc819050372a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.8726\n",
            "RMSE: 0.8725502428166245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Mean Absolute Error (MAE)is another metric for evaluating the accuracy of predicted ratings. It is less sensitive to outliers compared to RMSE.\n",
        "\n",
        "mae = accuracy.mae(predictions)\n",
        "print(f'MAE: {mae}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYqVl9dSTIAK",
        "outputId": "b90f0d5d-b1f0-46f8-9556-d8b06271e07d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE:  0.6698\n",
            "MAE: 0.6697988723251972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73CZG_0GWnCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision@K and Recall@K are used to evaluate the quality of top-N recommendations. Precision@K measures the proportion of recommended items that are relevant, while Recall@K measures the proportion of relevant items that are recommended.\n",
        "\n",
        "from collections import defaultdict #improting  defaultdict from collections\n",
        "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
        "    \"\"\"Return precision and recall at k metrics for each user.\"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    user_est_true = defaultdict(list)\n",
        "    for uid, _, true_r, est, _ in predictions:\n",
        "        user_est_true[uid].append((est, true_r))\n",
        "\n",
        "    precisions = dict()\n",
        "    recalls = dict()\n",
        "    for uid, user_ratings in user_est_true.items():\n",
        "        # Sort user ratings by estimated value\n",
        "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "        # Number of relevant items\n",
        "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
        "\n",
        "        # Number of recommended items in top k\n",
        "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
        "\n",
        "        # Number of relevant and recommended items in top k\n",
        "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
        "                              for (est, true_r) in user_ratings[:k])\n",
        "\n",
        "        # Precision@K: Proportion of recommended items that are relevant\n",
        "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
        "\n",
        "        # Recall@K: Proportion of relevant items that are recommended\n",
        "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
        "\n",
        "    return precisions, recalls\n",
        "\n",
        "# Example usage\n",
        "precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=3.5)\n",
        "print(f'Precision@10: {sum(prec for prec in precisions.values()) / len(precisions)}')\n",
        "print(f'Recall@10: {sum(rec for rec in recalls.values()) / len(recalls)}')\n"
      ],
      "metadata": {
        "id": "juD3DCYNTf7N",
        "outputId": "638d984f-4830-499c-bd02-f52f9c33a5b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@10: 0.8036865729898521\n",
            "Recall@10: 0.5181959760448667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  F1-Score is the harmonic mean of precision and recall, providing a single metric that balances both.\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np # import numpy for array operations\n",
        "\n",
        "\n",
        "# Assuming 'predictions' contains the output of your model\n",
        "# Extract true and predicted ratings\n",
        "true_ratings = [pred.r_ui for pred in predictions]  # True ratings\n",
        "predicted_ratings = [pred.est for pred in predictions]  # Predicted ratings\n",
        "\n",
        "# If you need binary relevance (relevant/not relevant):\n",
        "threshold = 3.5  # Example threshold for relevance\n",
        "# Convert true_ratings to a NumPy array before comparison\n",
        "true_labels = np.array(true_ratings) >= threshold\n",
        "# Convert predicted_ratings to a NumPy array before comparison\n",
        "predicted_labels = np.array(predicted_ratings) >= threshold\n",
        "\n",
        "# Calculate the F1-score\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "print(f'F1-Score: {f1}')"
      ],
      "metadata": {
        "id": "6su_zrIEUF-B",
        "outputId": "6f81011b-702b-4c5e-b033-2d41ef4a1786",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.736370360701388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Average Precision (MAP) is another metric that evaluates the quality of ranked recommendations. It is particularly useful when you have a list of recommended items and you want to evaluate how well the relevant items are ranked.\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Assuming you have already trained your model and made predictions\n",
        "predictions = svd.test(testset)\n",
        "\n",
        "# Assuming you have binary relevance labels (1 for relevant, 0 for not relevant)\n",
        "# Extract true and predicted ratings\n",
        "true_ratings = [pred.r_ui for pred in predictions]  # True ratings\n",
        "predicted_ratings = [pred.est for pred in predictions]  # Predicted ratings\n",
        "\n",
        "# If you need binary relevance (relevant/not relevant):\n",
        "threshold = 3.5  # Example threshold for relevance\n",
        "# Convert true_ratings to a NumPy array before comparison\n",
        "true_labels = np.array(true_ratings) >= threshold\n",
        "# Convert predicted_ratings to a NumPy array before comparison\n",
        "predicted_labels = np.array(predicted_ratings) >= threshold\n",
        "\n",
        "# Use predicted_ratings (or predicted_labels for binary case) as predicted scores\n",
        "map_score = average_precision_score(true_labels, predicted_ratings) # Using predicted_ratings as scores\n",
        "\n",
        "print(f'Mean Average Precision: {map_score}')\n"
      ],
      "metadata": {
        "id": "PViDeQxIVH3I",
        "outputId": "781dd33b-b189-4522-ea10-0871c813db1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision: 0.8367234335785432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized Discounted Cumulative Gain (NDCG) is used to evaluate the ranking quality of recommendations. It gives more weight to relevant items that appear higher in the recommendation list.\n",
        "\n",
        "from sklearn.metrics import ndcg_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have already trained your model and made predictions\n",
        "predictions = svd.test(testset)\n",
        "\n",
        "# Extract true and predicted ratings\n",
        "true_ratings = [pred.r_ui for pred in predictions]  # True ratings\n",
        "predicted_ratings = [pred.est for pred in predictions]  # Predicted ratings\n",
        "\n",
        "# Use true_ratings as true relevance scores\n",
        "# You may need to adjust this if your relevance scores are different\n",
        "true_relevance_scores = np.array([true_ratings])  # Reshape to 2D array\n",
        "\n",
        "# Use predicted_ratings as predicted scores\n",
        "predicted_scores = np.array([predicted_ratings])  # Reshape to 2D array\n",
        "\n",
        "# Calculate NDCG\n",
        "ndcg = ndcg_score(true_relevance_scores, predicted_scores)\n",
        "print(f'NDCG: {ndcg}')"
      ],
      "metadata": {
        "id": "N-eNo6MdVYMB",
        "outputId": "1e257fe1-c3fd-46e6-8935-3c507cab9756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG: 0.9875286675093949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Coverage measures the percentage of items in the catalog that the recommendation system is able to recommend.\n",
        "\n",
        "def coverage(predictions, catalog_size):\n",
        "    recommended_items = set()\n",
        "    for uid, _, _, est, _ in predictions:\n",
        "        if est >= threshold:\n",
        "            recommended_items.add(uid)\n",
        "    return len(recommended_items) / catalog_size\n",
        "\n",
        "# Example usage\n",
        "catalog_size = len(movies['movieId'].unique())\n",
        "coverage_score = coverage(predictions, catalog_size)\n",
        "print(f'Coverage: {coverage_score}')"
      ],
      "metadata": {
        "id": "3YzD6TqKVl9y",
        "outputId": "b69de71e-acca-40c9-ed40-1dcf5302b805",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage: 0.058823529411764705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Diversity measures how different the recommended items are from each other. It can be calculated using various methods, such as cosine similarity or Jaccard similarity.\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def diversity(recommended_items):\n",
        "    # This is a placeholder, replace with your actual item vector function\n",
        "    def item_vector(item):\n",
        "        # This could represent features like genre, actors, etc.\n",
        "        # For example, you might have a dictionary mapping item IDs to vectors\n",
        "        # item_vectors = {1: [0.2, 0.5, 0.8], 2: [0.1, 0.7, 0.3], ...}\n",
        "        # Then you can return item_vectors.get(item, [])  # Default to empty vector if not found\n",
        "        return [0.1, 0.2, 0.3] # Replace with your logic to get the vector for an item\n",
        "\n",
        "    item_vectors = [item_vector(item) for item in recommended_items]\n",
        "    similarity_matrix = cosine_similarity(item_vectors)\n",
        "    return 1 - similarity_matrix.mean()\n",
        "\n",
        "# Example usage:\n",
        "# Define a list of recommended items. These could be movie IDs, product IDs, etc.\n",
        "# Replace with the actual output from your recommendation system\n",
        "recommended_items = [1, 2, 3, 4, 5]\n",
        "\n",
        "diversity_score = diversity(recommended_items)\n",
        "print(f'Diversity: {diversity_score}')"
      ],
      "metadata": {
        "id": "pvUuSQL8Ws5S",
        "outputId": "8124176d-5304-4b4d-be57-1753dff62cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diversity: 1.1102230246251565e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Serendipity measures how surprising the recommendations are to the user. It can be calculated by comparing the recommendations to the user's historical preferences.\n",
        "\n",
        "def serendipity(user_history, recommended_items):\n",
        "    unexpected_items = [item for item in recommended_items if item not in user_history]\n",
        "    return len(unexpected_items) / len(recommended_items)\n",
        "\n",
        "# Example usage\n",
        "user_history = set(movies[movies['userId'] == user_id]['movieId'])\n",
        "serendipity_score = serendipity(user_history, recommended_items)\n",
        "print(f'Serendipity: {serendipity_score}')"
      ],
      "metadata": {
        "id": "qwyoJOXcXMXl",
        "outputId": "ca654b27-1829-43a7-f475-509fe0e15422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Serendipity: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User Satisfaction (via A/B Testing)\n",
        "\n",
        "# Example of A/B testing setup\n",
        "# Group A: Control group (existing recommendation system)\n",
        "# Group B: Test group (new recommendation system)\n",
        "\n",
        "# You'll need to define the 'calculate_ctr' function first.\n",
        "# It should take a group (A or B) as input and return the CTR.\n",
        "def calculate_ctr(group):\n",
        "  \"\"\"\n",
        "  Calculates the Click-Through Rate (CTR) for a group.\n",
        "\n",
        "  Args:\n",
        "    group: The group data (e.g., list of user interactions).\n",
        "\n",
        "  Returns:\n",
        "    The CTR for the group.\n",
        "  \"\"\"\n",
        "  # Replace this with your logic to calculate CTR.\n",
        "  # For example, you might have:\n",
        "  # clicks = sum(1 for interaction in group if interaction['clicked'])\n",
        "  # impressions = len(group)\n",
        "  # ctr = clicks / impressions if impressions else 0\n",
        "  # return ctr\n",
        "  # Here, I'm using a placeholder value.\n",
        "  return 0.1  # Placeholder CTR value\n",
        "\n",
        "# Example Data for groups (replace with your actual data)\n",
        "group_A = []  # Control group\n",
        "group_B = []  # Test group\n",
        "\n",
        "# Measure CTR for both groups\n",
        "ctr_A = calculate_ctr(group_A)\n",
        "ctr_B = calculate_ctr(group_B)\n",
        "\n",
        "print(f'CTR for Group A: {ctr_A}')\n",
        "print(f'CTR for Group B: {ctr_B}')"
      ],
      "metadata": {
        "id": "OLiZi77-XT8s",
        "outputId": "bdfe41fd-f4a1-4d34-92a2-1d4fbe935f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CTR for Group A: 0.1\n",
            "CTR for Group B: 0.1\n"
          ]
        }
      ]
    }
  ]
}