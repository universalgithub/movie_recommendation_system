{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abiralchy0987/movie_recommendation_system/blob/main/Full_recommendation_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C90vVBxWjttz",
        "outputId": "1f34f4ca-6c1c-4864-dc67-5aaff0432a12",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-bc96b97cf622>:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
            "<ipython-input-4-bc96b97cf622>:110: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())\n",
            "<ipython-input-4-bc96b97cf622>:122: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['tags'] = new_df['tags'].apply(stem)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['when', 'when the', 'when the daughter', 'when the daughter of', 'when the daughter of a', 'when the daughter of a psychiatrist', 'when the daughter of a psychiatrist is', 'when the daughter of a psychiatrist is kidnapped,', \"when the daughter of a psychiatrist is kidnapped, he'\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors'\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret..\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist killer\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist killer thriller\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist killer thriller michaeldougla\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist killer thriller michaeldougla seanbean\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist killer thriller michaeldougla seanbean brittanymurphi\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspen psychiatrist killer thriller michaeldougla seanbean brittanymurphi garyfl\", \"when the daughter of a psychiatrist is kidnapped, he' horrifi to discov that the abductors' demand is that he break through to a post traumat stress disord suffer young woman who know a secret.. cemeteri diamant suspens psychiatrist killer thriller michaeldougla seanbean brittanymurphi garyfled\"]\n",
            "Spider-Man 3\n",
            "Spider-Man 2\n",
            "The Amazing Spider-Man 2\n",
            "The Amazing Spider-Man\n",
            "X-Men\n"
          ]
        }
      ],
      "source": [
        "# Content filtering\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import os\n",
        "\n",
        "#reading the data\n",
        "movies = pd.read_csv('/content/tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('/content/tmdb_5000_credits.csv')\n",
        "\n",
        "movies.head(2)\n",
        "\n",
        "#head shows only one row of the dataset because of the parameter (1)\n",
        "credits.head(1)\n",
        "\n",
        "movies.shape\n",
        "\n",
        "#shape shows how many rows and columns are available in the dataset\n",
        "credits.shape\n",
        "\n",
        "#integration of datasets movies and credits\n",
        "movies = movies.merge(credits , on = 'title')\n",
        "\n",
        "movies.head(1)\n",
        "\n",
        "#visualising the integrated datasets\n",
        "#previously movies had 20 columns and credits had four columns and since\n",
        "#it was integrated on the column \"title\" which was same on both the datasets\n",
        "#the new number of columns present is 23\n",
        "movies.shape\n",
        "\n",
        "\n",
        "movies.columns\n",
        "\n",
        "#cleaning data\n",
        "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
        "\n",
        "#data preprocessing\n",
        "#checking for missing values\n",
        "movies.isnull().sum()\n",
        "\n",
        "#dropping the rows with missing value because there is very small number of data with missing value\n",
        "movies.dropna(inplace=True)\n",
        "\n",
        "movies.duplicated().sum()\n",
        "\n",
        "movies.iloc[0]['genres']\n",
        "\n",
        "import ast\n",
        "def convert(text):\n",
        "  l=[]\n",
        "  for i in ast.literal_eval(text):\n",
        "    l.append(i['name'])\n",
        "\n",
        "  return l\n",
        "\n",
        "\n",
        "movies['genres']=movies['genres'].apply(convert)\n",
        "\n",
        "movies['keywords']=movies['keywords'].apply(convert)\n",
        "\n",
        "import ast\n",
        "def convert_cast(text):\n",
        "  l=[]\n",
        "  counter=0\n",
        "  for i in ast.literal_eval(text):\n",
        "    if counter<3:\n",
        "     l.append(i['name'])\n",
        "    counter+=1\n",
        "\n",
        "  return l\n",
        "\n",
        "movies['cast']=movies['cast'].apply(convert_cast)\n",
        "\n",
        "import ast\n",
        "def fetch_director(text):\n",
        "  l=[]\n",
        "  for i in ast.literal_eval(text):\n",
        "    if i['job'] == 'Director':\n",
        "     l.append(i['name'])\n",
        "     break\n",
        "\n",
        "  return l\n",
        "\n",
        "movies['crew']=movies['crew'].apply(fetch_director)\n",
        "\n",
        "\n",
        "\n",
        "movies['overview']=movies['overview'].apply(lambda x:x.split())\n",
        "\n",
        "def remove_space(word):\n",
        "  l = []\n",
        "  for i in word:\n",
        "    l.append(i.replace(\" \",\"\"))\n",
        "  return l\n",
        "\n",
        "\n",
        "movies['cast']=movies['cast'].apply(remove_space)\n",
        "\n",
        "movies['crew']=movies['crew'].apply(remove_space)\n",
        "\n",
        "movies['tags']= movies['overview']+movies['keywords']+movies['genres']+movies['cast']+movies['crew']\n",
        "\n",
        "new_df = movies[['movie_id','title','tags']]\n",
        "\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "def stem(text):\n",
        "  l = []\n",
        "  for i in text.split():\n",
        "    l.append(ps.stem(i))\n",
        "\n",
        "  return \" \".join(l)\n",
        "\n",
        "new_df['tags'] = new_df['tags'].apply(stem)\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "words_clean=[]\n",
        "for word in new_df['tags']:\n",
        " stopwords = nltk.corpus.stopwords.words('english')\n",
        "if word not in stopwords:\n",
        "     l = []\n",
        "for i in word.split():\n",
        "     l.append(ps.stem(i))\n",
        "     words_clean.append(\" \".join(l))\n",
        "else:\n",
        "         words_clean.append(word)\n",
        "         print(words_clean)\n",
        "# def stem(text):\n",
        "#   l = []\n",
        "#   for i in text.split():\n",
        "#     l.append(ps.stem(i))\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=5000,stop_words='english')\n",
        "vector= cv.fit_transform(new_df['tags']).toarray()\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity = cosine_similarity(vector)\n",
        "similarity\n",
        "\n",
        "new_df[new_df['title'] == 'Spider-Man'].index[0]\n",
        "\n",
        "def recommend(movie):\n",
        "  movie_index = new_df[new_df['title'] == movie].index[0]\n",
        "  distances =sorted(list(enumerate(similarity[movie_index])),reverse=True, key = lambda x: x[1])\n",
        "  for i in distances[1:6]:\n",
        "    print(new_df.iloc[i[0]].title)\n",
        "\n",
        "\n",
        "recommend('Spider-Man')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#collaborative filtering\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "movies_df = pd.read_csv('movies.csv')\n",
        "ratings_df = pd.read_csv('ratings.csv')\n",
        "\n",
        "ratings_df.shape\n",
        "\n",
        "movies_df.head(1)\n",
        "\n",
        "ratings_df.head(1)\n",
        "\n",
        "movies = pd.merge(ratings_df, movies_df, on='movieId')\n",
        "\n",
        "\n",
        "# Remove duplicates if any\n",
        "movies = movies.drop_duplicates()\n",
        "\n",
        "\n",
        "# Create the User-Item Rating Matrix (pivot table)\n",
        "user_item_matrix = movies.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# Display the shape and first few entries of the matrix\n",
        "print(user_item_matrix.shape)\n",
        "print(user_item_matrix.head())\n",
        "\n",
        "\n",
        "# Calculate the global average rating\n",
        "global_avg_rating = movies['rating'].mean()\n",
        "\n",
        "# Fill NaN values with the global average rating\n",
        "user_item_matrix_filled = user_item_matrix.fillna(global_avg_rating)\n",
        "\n",
        "\n",
        "user_item_matrix_filled.head(1)\n",
        "\n",
        "!pip install scikit-surprise\n",
        "\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# Prepare data for Surprise\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(movies[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Split data into train and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.2)\n",
        "\n",
        "# Initialize SVD model\n",
        "svd = SVD()\n",
        "\n",
        "# Train the model\n",
        "svd.fit(trainset)\n",
        "\n",
        "# Predict ratings on the testset\n",
        "predictions = svd.test(testset)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "\n",
        "# Predict the rating for a specific user-item pair\n",
        "user_id = 1  # Example user\n",
        "movie_id = 50  # Example movie\n",
        "\n",
        "predicted_rating = svd.predict(user_id, movie_id).est\n",
        "print(f\"Predicted rating for User {user_id} on Movie {movie_id}: {predicted_rating}\")\n",
        "\n",
        "\n",
        "import heapq\n",
        "\n",
        "def recommend_movies(user_id, top_n=10):\n",
        "    \"\"\"Recommends top N movies for a specific user.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): The ID of the user.\n",
        "        top_n (int, optional): The number of movies to recommend. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of movie titles.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get all movie IDs and create a dictionary for movieId -> title lookup\n",
        "    movie_id_to_title = dict(zip(movies['movieId'], movies['title']))\n",
        "\n",
        "    # Get all unique movie IDs\n",
        "    all_movie_ids = movies['movieId'].unique()\n",
        "\n",
        "    # Get the movies that the user has already rated\n",
        "    rated_movies = set(movies[movies['userId'] == user_id]['movieId'])\n",
        "\n",
        "    # Get the unrated movies\n",
        "    unrated_movies = [movie_id for movie_id in all_movie_ids if movie_id not in rated_movies]\n",
        "\n",
        "    # Predict ratings for unrated movies\n",
        "    predictions = [svd.predict(user_id, movie_id) for movie_id in unrated_movies]\n",
        "\n",
        "    # Sort movies by predicted rating (highest first)\n",
        "    recommended_movies = heapq.nlargest(top_n, predictions, key=lambda x: x.est)\n",
        "\n",
        "    # Get movie titles from the top N predictions using the dictionary\n",
        "    movie_titles = [movie_id_to_title[rec.iid] for rec in recommended_movies]\n",
        "\n",
        "    return movie_titles\n",
        "\n",
        "# Example usage:\n",
        "user_id = 1  # Example user ID\n",
        "recommended_movies = recommend_movies(user_id, top_n=10)\n",
        "print(f\"Top 10 movie recommendations for User {user_id}: {recommended_movies}\")\n",
        "\n",
        "user_id_input = input(\"Enter your user ID: \")\n",
        "try:\n",
        "    user_id = int(user_id_input)  # Ensure the user ID is an integer\n",
        "    recommended_movies = recommend_movies(user_id, top_n=10)\n",
        "    print(f\"Top 10 movie recommendations for User {user_id}: {recommended_movies}\")\n",
        "except ValueError:\n",
        "    print(\"Invalid input. Please enter a valid integer for user ID.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MwMeX6jovdd",
        "outputId": "db546672-d3af-4a53-a9d0-eec237acb6b8",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610, 9724)\n",
            "movieId  1       2       3       4       5       6       7       8       \\\n",
            "userId                                                                    \n",
            "1           4.0     NaN     4.0     NaN     NaN     4.0     NaN     NaN   \n",
            "2           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "3           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "4           NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "5           4.0     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "\n",
            "movieId  9       10      ...  193565  193567  193571  193573  193579  193581  \\\n",
            "userId                   ...                                                   \n",
            "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "2           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "3           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "4           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "5           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
            "\n",
            "movieId  193583  193585  193587  193609  \n",
            "userId                                   \n",
            "1           NaN     NaN     NaN     NaN  \n",
            "2           NaN     NaN     NaN     NaN  \n",
            "3           NaN     NaN     NaN     NaN  \n",
            "4           NaN     NaN     NaN     NaN  \n",
            "5           NaN     NaN     NaN     NaN  \n",
            "\n",
            "[5 rows x 9724 columns]\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505174 sha256=58c9337ad217811ad588f990d218d10dd56bb061e427117b3ed22a21f0951652\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "RMSE: 0.8749\n",
            "RMSE: 0.8748696541356981\n",
            "Predicted rating for User 1 on Movie 50: 5\n",
            "Top 10 movie recommendations for User 1: ['Shawshank Redemption, The (1994)', 'Wallace & Gromit: The Best of Aardman Animation (1996)', 'Philadelphia Story, The (1940)', \"Singin' in the Rain (1952)\", 'Rear Window (1954)', 'Casablanca (1942)', 'Brazil (1985)', 'Amadeus (1984)', 'Godfather, The (1972)', \"One Flew Over the Cuckoo's Nest (1975)\"]\n",
            "Enter your user ID: 5\n",
            "Top 10 movie recommendations for User 5: ['Great Escape, The (1963)', 'Princess Bride, The (1987)', 'Wizard of Oz, The (1939)', 'Outlaw Josey Wales, The (1976)', 'High Noon (1952)', 'Raging Bull (1980)', 'Casablanca (1942)', 'Cool Hand Luke (1967)', 'Eastern Promises (2007)', 'Manchurian Candidate, The (1962)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install thefuzz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqH3EcT1srnL",
        "outputId": "bceba9a1-aa88-44e3-a17c-ed16cd662c58",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: thefuzz in /usr/local/lib/python3.11/dist-packages (0.22.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from thefuzz) (3.12.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from thefuzz import fuzz, process\n",
        "\n",
        "def find_closest_movie(title_input):\n",
        "    \"\"\"\n",
        "    Finds the closest matching movie title in new_df using fuzzy matching.\n",
        "    Both the user input and the titles are compared in lowercase.\n",
        "    \"\"\"\n",
        "    all_titles = new_df['title'].tolist()\n",
        "    # Create a lowercase version for fuzzy matching\n",
        "    all_titles_lower = [t.lower() for t in all_titles]\n",
        "    title_input_lower = title_input.lower().strip()\n",
        "\n",
        "    # Get the best match using fuzzy matching\n",
        "    best_match, score = process.extractOne(title_input_lower, all_titles_lower, scorer=fuzz.partial_ratio)\n",
        "\n",
        "    # Accept the match if the score is above a threshold (e.g., 60)\n",
        "    if score > 60:\n",
        "        # Return the original title (with proper casing) corresponding to the best match\n",
        "        match_index = all_titles_lower.index(best_match)\n",
        "        return new_df.iloc[match_index]['title']\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def hybrid_recommend(user_id, movie_title, top_n=10):\n",
        "    \"\"\"\n",
        "    Hybrid recommendation that returns half the recommendations from content-based filtering\n",
        "    and half from collaborative filtering.\n",
        "\n",
        "    Args:\n",
        "        user_id (int): The ID of the user (for collaborative filtering).\n",
        "        movie_title (str): The movie title used for content-based filtering (input is fuzzy-matched).\n",
        "        top_n (int): Total number of recommendations to return.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of recommended movie titles.\n",
        "    \"\"\"\n",
        "    # Determine how many movies to take from each recommender\n",
        "    n_content = top_n // 2\n",
        "    n_collab = top_n - n_content  # This ensures if top_n is odd, collaborative gets the extra slot\n",
        "\n",
        "    # ----------- Content-Based Filtering -----------\n",
        "    # Find the closest matching movie title\n",
        "    matched_movie = find_closest_movie(movie_title)\n",
        "    if not matched_movie:\n",
        "        print(f\"Sorry, we couldn't find a close match for '{movie_title}'. Please try another title.\")\n",
        "        return []\n",
        "\n",
        "    print(f\"Using content-based match: '{matched_movie}'\")\n",
        "\n",
        "    # Get the index for the matched movie from new_df\n",
        "    try:\n",
        "        movie_index = new_df[new_df['title'] == matched_movie].index[0]\n",
        "    except IndexError:\n",
        "        print(f\"Movie '{matched_movie}' not found in the dataset.\")\n",
        "        return []\n",
        "\n",
        "    # Get similarity scores for all movies relative to the matched movie\n",
        "    content_scores = list(enumerate(similarity[movie_index]))\n",
        "    # Sort scores in descending order (most similar first)\n",
        "    content_scores = sorted(content_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Build content-based recommendation list (skip the first entry as it is the movie itself)\n",
        "    content_recs = []\n",
        "    for idx, score in content_scores[1:]:\n",
        "        rec_title = new_df.iloc[idx]['title']\n",
        "        if rec_title not in content_recs:\n",
        "            content_recs.append(rec_title)\n",
        "        if len(content_recs) >= n_content:\n",
        "            break\n",
        "\n",
        "    # ----------- Collaborative Filtering -----------\n",
        "    # Get a larger pool from collaborative filtering so we can remove any duplicates later\n",
        "    collab_pool = recommend_movies(user_id, top_n=top_n * 2)\n",
        "    # Remove any movies that already appeared in the content-based recommendations\n",
        "    collab_recs = [m for m in collab_pool if m not in content_recs]\n",
        "    # Select the top n_collab recommendations\n",
        "    collab_recs = collab_recs[:n_collab]\n",
        "\n",
        "    # ----------- Merge Recommendations -----------\n",
        "    final_recs = content_recs + collab_recs\n",
        "\n",
        "    # In case there are not enough unique recommendations, try to fill from the collaborative pool\n",
        "    if len(final_recs) < top_n:\n",
        "        extra_needed = top_n - len(final_recs)\n",
        "        extra_from_collab = [m for m in collab_pool if m not in final_recs]\n",
        "        final_recs += extra_from_collab[:extra_needed]\n",
        "\n",
        "    return final_recs\n",
        "\n",
        "# ---------------------------\n",
        "# Example Usage\n",
        "# ---------------------------\n",
        "\n",
        "# Get user input\n",
        "try:\n",
        "    user_id = int(input(\"Enter your user ID: \"))\n",
        "except ValueError:\n",
        "    print(\"Invalid user ID. Please enter an integer value.\")\n",
        "    user_id = None\n",
        "\n",
        "if user_id is not None:\n",
        "    movie_title = input(\"Enter a movie title you like: \")\n",
        "\n",
        "    recommendations = hybrid_recommend(user_id, movie_title, top_n=10)\n",
        "\n",
        "    if recommendations:\n",
        "        print(\"\\nHybrid Recommendations (50% Content-Based, 50% Collaborative):\")\n",
        "        for i, title in enumerate(recommendations, 1):\n",
        "            print(f\"{i}. {title}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxxdG6frtScZ",
        "outputId": "07b55aad-1c87-4a8e-e3ea-992a85aeb5e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your user ID: 1\n",
            "Enter a movie title you like: batman\n",
            "Using content-based match: 'Batman v Superman: Dawn of Justice'\n",
            "\n",
            "Hybrid Recommendations (50% Content-Based, 50% Collaborative):\n",
            "1. Man of Steel\n",
            "2. Superman\n",
            "3. Batman Begins\n",
            "4. Suicide Squad\n",
            "5. Watchmen\n",
            "6. Shawshank Redemption, The (1994)\n",
            "7. Wallace & Gromit: The Best of Aardman Animation (1996)\n",
            "8. Philadelphia Story, The (1940)\n",
            "9. Singin' in the Rain (1952)\n",
            "10. Rear Window (1954)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Assuming `predictions` contains the predicted ratings and `testset` contains the actual ratings\n",
        "actual_ratings = [pred.r_ui for pred in predictions]\n",
        "predicted_ratings = [pred.est for pred in predictions]\n",
        "\n",
        "mae = mean_absolute_error(actual_ratings, predicted_ratings)\n",
        "rmse = mean_squared_error(actual_ratings, predicted_ratings)\n",
        "\n",
        "print(f'MAE: {mae}')\n",
        "print(f'RMSE: {rmse}')"
      ],
      "metadata": {
        "id": "Rb9CkkkKqXtq",
        "outputId": "5b17500f-a9ab-4a8e-d9c3-d747deffb11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.6718069924239145\n",
            "RMSE: 0.7653969117275159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming `recommended_movies` is a list of recommended movies and `relevant_movies` is a list of actual relevant movies\n",
        "# Define 'all_movies' based on the available movies in the dataset\n",
        "# This assumes that the movies in your dataset are in the 'movies' DataFrame\n",
        "all_movies = list(movies['title'].unique())  # Get unique movie titles\n",
        "\n",
        "# Update the relevant_movies variable to represent actual relevant movies for the user.\n",
        "# For this example, I'll assume a subset of movies are relevant:\n",
        "relevant_movies = ['Toy Story (1995)', 'Jumanji (1995)', 'Grumpier Old Men (1995)']\n",
        "\n",
        "# Update recommended_movies to represent movies recommended by the model.\n",
        "# For this example, I'll assume a subset of movies are recommended:\n",
        "recommended_movies = ['Toy Story (1995)', 'GoldenEye (1995)', 'Jumanji (1995)']\n",
        "\n",
        "# Calculate the predictions\n",
        "y_true = [1 if movie in relevant_movies else 0 for movie in all_movies]\n",
        "y_pred = [1 if movie in recommended_movies else 0 for movie in all_movies]\n",
        "\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-Score: {f1}')"
      ],
      "metadata": {
        "id": "EvNtOXt6ql7T",
        "outputId": "7a878efd-ee43-4552-e524-d91318f7fd91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6666666666666666\n",
            "Recall: 0.6666666666666666\n",
            "F1-Score: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def hit_rate(recommended_movies, relevant_movies):\n",
        "    hits = 0\n",
        "    for user_recs, user_relevant in zip(recommended_movies, relevant_movies):\n",
        "        if any(movie in user_relevant for movie in user_recs):\n",
        "            hits += 1\n",
        "    return hits / len(recommended_movies)\n",
        "\n",
        "hit_rate_value = hit_rate(recommended_movies, relevant_movies)\n",
        "print(f'Hit Rate: {hit_rate_value}')"
      ],
      "metadata": {
        "id": "IYyxScuIrvoE",
        "outputId": "bf25c83e-cc74-4f85-f2ce-934183d01a0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit Rate: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Assuming `y_true` and `y_pred` are binary relevance vectors\n",
        "map_score = average_precision_score(y_true, y_pred)\n",
        "print(f'Mean Average Precision: {map_score}')"
      ],
      "metadata": {
        "id": "8dTCo5HIq5ZH",
        "outputId": "3f8c15b4-25c2-43d5-cb94-bffa841db274",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision: 0.44454733568839955\n"
          ]
        }
      ]
    }
  ]
}