{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abiralchy0987/movie_recommendation_system/blob/main/Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLTPEoUDnU6i",
        "outputId": "178ecc2b-8484-4648-87b5-4e564823ab19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.27.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.3 streamlit-1.42.2 watchdog-6.0.0\n",
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2505180 sha256=a624a7c137dec59e2e5f2bc0aafc55f57a33ed1f010cc153f3f697b332d0a5b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Collecting thefuzz[speedup]\n",
            "  Downloading thefuzz-0.22.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.0.0 (from thefuzz[speedup])\n",
            "  Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading rapidfuzz-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thefuzz-0.22.1-py3-none-any.whl (8.2 kB)\n",
            "Installing collected packages: rapidfuzz, thefuzz\n",
            "Successfully installed rapidfuzz-3.12.1 thefuzz-0.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit pyngrok\n",
        "!pip install scikit-surprise\n",
        "!pip install thefuzz[speedup]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.set_page_config(page_title=\"Movie Recommender\", layout=\"wide\")\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from thefuzz import fuzz, process\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set page config\n",
        "\n",
        "# Cache data loading and preprocessing\n",
        "@st.cache_data\n",
        "def load_and_preprocess_data():\n",
        "    movies = pd.read_csv('tmdb_5000_movies.csv')\n",
        "    credits = pd.read_csv('tmdb_5000_credits.csv')\n",
        "    movies = movies.merge(credits, on='title')\n",
        "    movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
        "    movies.dropna(inplace=True)\n",
        "\n",
        "    def convert(text):\n",
        "        return [i['name'] for i in ast.literal_eval(text)]\n",
        "\n",
        "    def convert_cast(text):\n",
        "        return [i['name'] for i in ast.literal_eval(text)[:3]]\n",
        "\n",
        "    def fetch_director(text):\n",
        "        return [i['name'] for i in ast.literal_eval(text) if i['job'] == 'Director'][:1]\n",
        "\n",
        "    movies['genres'] = movies['genres'].apply(convert)\n",
        "    movies['keywords'] = movies['keywords'].apply(convert)\n",
        "    movies['cast'] = movies['cast'].apply(convert_cast)\n",
        "    movies['crew'] = movies['crew'].apply(fetch_director)\n",
        "    movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
        "\n",
        "    movies['tags'] = movies['overview'] + movies['keywords'] + movies['genres'] + movies['cast'] + movies['crew']\n",
        "    movies['tags'] = movies['tags'].apply(lambda x: ' '.join(x).lower())\n",
        "\n",
        "    ps = PorterStemmer()\n",
        "    movies['tags'] = movies['tags'].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
        "\n",
        "    cv = CountVectorizer(max_features=5000, stop_words='english')\n",
        "    vectors = cv.fit_transform(movies['tags']).toarray()\n",
        "    similarity = cosine_similarity(vectors)\n",
        "\n",
        "    return movies, similarity\n",
        "\n",
        "@st.cache_resource\n",
        "def train_collaborative_model():\n",
        "    ratings = pd.read_csv('ratings.csv')\n",
        "    movies_df = pd.read_csv('movies.csv')\n",
        "    movies_merged = pd.merge(ratings, movies_df, on='movieId')\n",
        "\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    data = Dataset.load_from_df(movies_merged[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data.build_full_trainset()\n",
        "    svd = SVD()\n",
        "    svd.fit(trainset)\n",
        "\n",
        "    return svd, movies_merged\n",
        "\n",
        "movies_df, similarity = load_and_preprocess_data()\n",
        "svd_model, merged_data = train_collaborative_model()\n",
        "\n",
        "def find_closest_movie(title_input):\n",
        "    all_titles = movies_df['title'].tolist()\n",
        "    best_match, score = process.extractOne(title_input.lower(), [t.lower() for t in all_titles], scorer=fuzz.partial_ratio)\n",
        "    return all_titles[[t.lower() for t in all_titles].index(best_match)] if score > 60 else None\n",
        "\n",
        "def hybrid_recommend(user_id, movie_title, top_n=10):\n",
        "    matched_movie = find_closest_movie(movie_title)\n",
        "    if not matched_movie:\n",
        "        return []\n",
        "\n",
        "    movie_index = movies_df[movies_df['title'] == matched_movie].index[0]\n",
        "    content_recs = [movies_df.iloc[i[0]]['title'] for i in\n",
        "                   sorted(enumerate(similarity[movie_index]), key=lambda x: x[1], reverse=True)[1:6]]\n",
        "\n",
        "    user_rated = set(merged_data[merged_data['userId'] == user_id]['movieId'])\n",
        "    all_movies = merged_data['movieId'].unique()\n",
        "    unrated = [mid for mid in all_movies if mid not in user_rated]\n",
        "    collab_recs = [merged_data[merged_data['movieId'] == mid]['title'].values[0]\n",
        "                  for mid in unrated[:10]]\n",
        "\n",
        "    return list(set(content_recs + collab_recs))[:top_n]\n",
        "\n",
        "st.title(\"🎬 Hybrid Movie Recommender System\")\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "with col1:\n",
        "    user_id = st.number_input(\"Enter User ID\", min_value=1, value=1, step=1)\n",
        "\n",
        "with col2:\n",
        "    movie_title = st.text_input(\"Enter a Movie Title\", \"The Dark Knight\")\n",
        "\n",
        "if st.button(\"Get Recommendations\"):\n",
        "    if user_id and movie_title:\n",
        "        with st.spinner('Finding best recommendations...'):\n",
        "            recommendations = hybrid_recommend(user_id, movie_title)\n",
        "\n",
        "        if recommendations:\n",
        "            st.subheader(\"Recommended Movies:\")\n",
        "            for i, title in enumerate(recommendations, 1):\n",
        "                st.markdown(f\"{i}. {title}\")\n",
        "        else:\n",
        "            st.warning(\"No recommendations found. Please try a different movie title.\")\n",
        "    else:\n",
        "        st.error(\"Please fill in both fields\")\n",
        "\n",
        "st.markdown(\"---\")\n",
        "st.write(\"### Dataset Information\")\n",
        "st.write(\"Content-based data shape:\", movies_df.shape)\n",
        "st.write(\"Collaborative data shape:\", merged_data.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD5XX8OLo51Q",
        "outputId": "b6b69594-585e-48cb-f7b4-300768d909c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &> log.txt &\n"
      ],
      "metadata": {
        "id": "UWfI3eTuo_65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import signal\n",
        "\n",
        "# Find and kill existing ngrok processes\n",
        "for line in os.popen(\"ps ax | grep ngrok | grep -v grep\"):\n",
        "    fields = line.split()\n",
        "    pid = fields[0]\n",
        "    os.kill(int(pid), signal.SIGKILL)\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your authtoken\n",
        "ngrok.set_auth_token(\"2tJWKmagjWWC5BYwbAxgWdXy8Fq_rvKfmHk7puUZAZHyY6WD\") # Replace YOUR_AUTHTOKEN with your actual authtoken\n",
        "\n",
        "# Start a new tunnel to port 8501 (default Streamlit port)\n",
        "# Specify the port within a configuration dictionary for HTTP/2 tunnels\n",
        "tunnel = ngrok.connect(8501, proto=\"http\", bind_tls=True)\n",
        "# or\n",
        "# tunnel = ngrok.connect(addr=\"http://localhost:8501\", bind_tls=True)\n",
        "\n",
        "public_url = tunnel.public_url\n",
        "\n",
        "print(f\"Streamlit App is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "donzesE3sc6l",
        "outputId": "41b39f2b-7acd-4d53-9774-f08f5f562681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit App is live at: https://b1c5-34-86-210-137.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FDFXVKGjSoQN",
        "outputId": "fd32197e-7aa3-45cb-c297-993115eef697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXUWxJTUsnWS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}