{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abiralchy0987/movie_recommendation_system/blob/main/optimized_CF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import ast\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load SpaCy's English model with disabled components for efficiency\n",
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "# Reading the data\n",
        "movies = pd.read_csv('/content/tmdb_5000_movies.csv')\n",
        "credits = pd.read_csv('/content/tmdb_5000_credits.csv')\n",
        "\n",
        "# Merge datasets using movie_id in 'credits' and 'id' in 'movies'\n",
        "movies_merged = movies.merge(credits, left_on='id', right_on='movie_id')\n",
        "\n",
        "# Select relevant columns and rename for clarity\n",
        "movies = movies_merged[['movie_id', 'title_x', 'overview', 'genres', 'keywords', 'cast', 'crew']]\n",
        "movies = movies.rename(columns={'title_x': 'title'})\n",
        "\n",
        "# Drop rows with missing values\n",
        "movies.dropna(inplace=True)\n",
        "\n",
        "# Safely convert JSON-like strings to lists\n",
        "def convert(text):\n",
        "    try:\n",
        "        return [i['name'] for i in ast.literal_eval(text)]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []  # Return empty list if parsing fails\n",
        "\n",
        "movies['genres'] = movies['genres'].apply(convert)\n",
        "movies['keywords'] = movies['keywords'].apply(convert)\n",
        "\n",
        "# Convert cast to a list of top 3 actors\n",
        "def convert_cast(text):\n",
        "    try:\n",
        "        return [i['name'] for i in ast.literal_eval(text)[:3]]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "\n",
        "movies['cast'] = movies['cast'].apply(convert_cast)\n",
        "\n",
        "# Fetch director from crew\n",
        "def fetch_director(text):\n",
        "    try:\n",
        "        for i in ast.literal_eval(text):\n",
        "            if i['job'] == 'Director':\n",
        "                return [i['name']]\n",
        "    except (ValueError, SyntaxError):\n",
        "        return []\n",
        "    return []\n",
        "\n",
        "movies['crew'] = movies['crew'].apply(fetch_director)\n",
        "\n",
        "# Process text: replace spaces with underscores\n",
        "def process_text(text):\n",
        "    return [i.replace(\" \", \"_\") for i in text]\n",
        "\n",
        "movies['cast'] = movies['cast'].apply(process_text)\n",
        "movies['crew'] = movies['crew'].apply(process_text)\n",
        "\n",
        "# Convert 'overview' to a list of words\n",
        "movies['overview'] = movies['overview'].apply(lambda x: x.split())\n",
        "\n",
        "# Combine all features into 'tags' as lists\n",
        "movies['tags'] = (\n",
        "    movies['overview'] +\n",
        "    movies['genres'].apply(lambda x: x * 2) +  # Weight genres\n",
        "    movies['keywords'].apply(lambda x: x * 2) +  # Weight keywords\n",
        "    movies['cast'].apply(lambda x: x * 3) +  # Weight cast\n",
        "    movies['crew'].apply(lambda x: x * 3)  # Weight crew\n",
        ")\n",
        "\n",
        "# Convert 'tags' to a single string\n",
        "movies['tags'] = movies['tags'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Use SpaCy's nlp.pipe for batch processing\n",
        "def preprocess_text_batch(texts):\n",
        "    processed_texts = []\n",
        "    for doc in nlp.pipe(texts, batch_size=50):\n",
        "        processed_tokens = [\n",
        "            token.lemma_.lower() for token in doc\n",
        "            if not token.is_stop and not token.is_punct\n",
        "        ]\n",
        "        processed_texts.append(\" \".join(processed_tokens))\n",
        "    return processed_texts\n",
        "\n",
        "# Apply batch preprocessing to 'tags'\n",
        "movies['tags'] = preprocess_text_batch(movies['tags'])\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1, 3),\n",
        "    min_df=0.001,\n",
        "    max_df=0.8,\n",
        "    stop_words='english'\n",
        ")\n",
        "vectors = tfidf.fit_transform(movies['tags'])\n",
        "\n",
        "# Compute cosine similarity\n",
        "similarity = cosine_similarity(vectors)\n",
        "\n",
        "# Recommendation function\n",
        "def recommend(movie, num_recommendations=5):\n",
        "    index = movies[movies['title'] == movie].index\n",
        "    if len(index) == 0:\n",
        "        return f\"Movie '{movie}' not found in database\"\n",
        "\n",
        "    index = index[0]  # Get the first index safely\n",
        "    sim_scores = list(enumerate(similarity[index]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    recommendations = [\n",
        "        {'title': movies.iloc[i[0]]['title'], 'similarity': f\"{i[1] * 100:.1f}%\"}\n",
        "        for i in sim_scores[1:num_recommendations + 1]\n",
        "    ]\n",
        "\n",
        "    return pd.DataFrame(recommendations)\n",
        "\n",
        "# Example usage\n",
        "print(recommend('Avatar'))"
      ],
      "metadata": {
        "id": "7xLE_mTJZkWH",
        "outputId": "d05b030e-77d3-4a58-ec9f-4faaf29b8e43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     title similarity\n",
            "0                   Aliens      43.2%\n",
            "1                   AlienÂ³      35.1%\n",
            "2  Star Trek Into Darkness      31.0%\n",
            "3                    Alien      30.2%\n",
            "4           Silent Running      29.4%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_at_k(movie_title, k=5, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate precision@k and recall@k for a given movie.\n",
        "\n",
        "    Args:\n",
        "        movie_title (str): The movie title to evaluate.\n",
        "        k (int): Number of recommendations to consider.\n",
        "        threshold (float): Similarity threshold for relevance.\n",
        "\n",
        "    Returns:\n",
        "        precision (float): Precision@k.\n",
        "        recall (float): Recall@k.\n",
        "    \"\"\"\n",
        "    # Get the index of the movie\n",
        "    index = movies[movies['title'] == movie_title].index\n",
        "    if len(index) == 0:\n",
        "        return 0, 0  # Movie not found\n",
        "\n",
        "    index = index[0]\n",
        "    sim_scores = list(enumerate(similarity[index]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get top-k recommendations (excluding the movie itself)\n",
        "    top_k_indices = [i[0] for i in sim_scores[1:k+1]]\n",
        "    top_k_scores = [i[1] for i in sim_scores[1:k+1]]\n",
        "\n",
        "    # Count relevant recommendations (similarity score > threshold)\n",
        "    relevant = sum(score > threshold for score in top_k_scores)\n",
        "\n",
        "    # Precision@k: Proportion of recommended items that are relevant\n",
        "    precision = relevant / k\n",
        "\n",
        "    # Recall@k: Proportion of relevant items that are recommended\n",
        "    # Total relevant items is the number of movies with similarity > threshold\n",
        "    total_relevant = sum(score > threshold for score in [i[1] for i in sim_scores[1:]])\n",
        "    recall = relevant / total_relevant if total_relevant > 0 else 0\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "# Example usage\n",
        "movie_title = 'Avatar'\n",
        "precision, recall = precision_recall_at_k(movie_title, k=5, threshold=0.5)\n",
        "print(f\"Precision@5: {precision:.2f}\")\n",
        "print(f\"Recall@5: {recall:.2f}\")"
      ],
      "metadata": {
        "id": "967rG5GqaQbT",
        "outputId": "3b899643-eca2-406b-825d-0842d010846b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision@5: 0.00\n",
            "Recall@5: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1_score(precision, recall):\n",
        "    \"\"\"\n",
        "    Calculate F1-score given precision and recall.\n",
        "\n",
        "    Args:\n",
        "        precision (float): Precision@k.\n",
        "        recall (float): Recall@k.\n",
        "\n",
        "    Returns:\n",
        "        f1 (float): F1-score.\n",
        "    \"\"\"\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Example usage\n",
        "f1 = f1_score(precision, recall)\n",
        "print(f\"F1-Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "rt4Nt7sJaaay",
        "outputId": "a7c26cc0-a85b-419d-8751-7edaafc295d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def coverage(similarity_matrix, k=5):\n",
        "    \"\"\"\n",
        "    Calculate coverage of the recommendation system.\n",
        "\n",
        "    Args:\n",
        "        similarity_matrix (numpy array): Cosine similarity matrix.\n",
        "        k (int): Number of recommendations to consider.\n",
        "\n",
        "    Returns:\n",
        "        coverage (float): Percentage of items that can be recommended.\n",
        "    \"\"\"\n",
        "    num_movies = similarity_matrix.shape[0]\n",
        "    recommended_items = set()\n",
        "\n",
        "    for i in range(num_movies):\n",
        "        sim_scores = list(enumerate(similarity_matrix[i]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        top_k_indices = [i[0] for i in sim_scores[1:k+1]]\n",
        "        recommended_items.update(top_k_indices)\n",
        "\n",
        "    return len(recommended_items) / num_movies\n",
        "\n",
        "# Example usage\n",
        "coverage_score = coverage(similarity, k=5)\n",
        "print(f\"Coverage: {coverage_score * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "9lf2fn8DanUM",
        "outputId": "924e2305-8a65-4f61-d5b2-4070024762b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage: 94.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_average_precision(movie_titles, k=5, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate Mean Average Precision (MAP) for a list of movies.\n",
        "\n",
        "    Args:\n",
        "        movie_titles (list): List of movie titles to evaluate.\n",
        "        k (int): Number of recommendations to consider.\n",
        "        threshold (float): Similarity threshold for relevance.\n",
        "\n",
        "    Returns:\n",
        "        map_score (float): Mean Average Precision.\n",
        "    \"\"\"\n",
        "    ap_scores = []\n",
        "\n",
        "    for movie_title in movie_titles:\n",
        "        precision, _ = precision_recall_at_k(movie_title, k, threshold)\n",
        "        ap_scores.append(precision)\n",
        "\n",
        "    return np.mean(ap_scores)\n",
        "\n",
        "# Example usage\n",
        "movie_titles = ['Avatar', 'Inception', 'The Dark Knight']\n",
        "map_score = mean_average_precision(movie_titles, k=5, threshold=0.5)\n",
        "print(f\"Mean Average Precision (MAP): {map_score:.2f}\")"
      ],
      "metadata": {
        "id": "fK7WMTwPatQc",
        "outputId": "b9544685-8b6b-4870-ac91-1e588c7340be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision (MAP): 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diversity(similarity_matrix, k=5):\n",
        "    \"\"\"\n",
        "    Calculate diversity of recommendations.\n",
        "\n",
        "    Args:\n",
        "        similarity_matrix (numpy array): Cosine similarity matrix.\n",
        "        k (int): Number of recommendations to consider.\n",
        "\n",
        "    Returns:\n",
        "        diversity_score (float): Average pairwise dissimilarity of recommendations.\n",
        "    \"\"\"\n",
        "    num_movies = similarity_matrix.shape[0]\n",
        "    diversity_scores = []\n",
        "\n",
        "    for i in range(num_movies):\n",
        "        sim_scores = list(enumerate(similarity_matrix[i]))\n",
        "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "        top_k_indices = [i[0] for i in sim_scores[1:k+1]]\n",
        "\n",
        "        # Calculate pairwise similarity between top-k recommendations\n",
        "        pairwise_similarity = np.mean([similarity_matrix[i][j] for i in top_k_indices for j in top_k_indices if i != j])\n",
        "        diversity_scores.append(1 - pairwise_similarity)  # Dissimilarity\n",
        "\n",
        "    return np.mean(diversity_scores)\n",
        "\n",
        "# Example usage\n",
        "diversity_score = diversity(similarity, k=5)\n",
        "print(f\"Diversity: {diversity_score:.2f}\")"
      ],
      "metadata": {
        "id": "ASCIwVPJavsl",
        "outputId": "17a2e979-f4fc-4aa4-b977-b6149f41dcd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diversity: 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate for a list of movies\n",
        "movie_titles = ['Avatar', 'Inception', 'The Dark Knight']\n",
        "\n",
        "# Calculate metrics\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "f1_list = []\n",
        "\n",
        "for movie_title in movie_titles:\n",
        "    precision, recall = precision_recall_at_k(movie_title, k=5, threshold=0.5)\n",
        "    f1 = f1_score(precision, recall)\n",
        "\n",
        "    precision_list.append(precision)\n",
        "    recall_list.append(recall)\n",
        "    f1_list.append(f1)\n",
        "\n",
        "# Print results\n",
        "print(f\"Average Precision@5: {np.mean(precision_list):.2f}\")\n",
        "print(f\"Average Recall@5: {np.mean(recall_list):.2f}\")\n",
        "print(f\"Average F1-Score: {np.mean(f1_list):.2f}\")\n",
        "print(f\"Coverage: {coverage(similarity, k=5) * 100:.2f}%\")\n",
        "print(f\"Diversity: {diversity(similarity, k=5):.2f}\")"
      ],
      "metadata": {
        "id": "T85MGS_-a0ak",
        "outputId": "8a72b1b9-f8f3-4eab-964c-0ebe22b46921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision@5: 0.13\n",
            "Average Recall@5: 0.33\n",
            "Average F1-Score: 0.19\n",
            "Coverage: 94.25%\n",
            "Diversity: 0.83\n"
          ]
        }
      ]
    }
  ]
}